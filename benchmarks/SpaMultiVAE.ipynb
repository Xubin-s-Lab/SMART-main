{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f20649-ad7c-4c79-a5a4-dbf2510504f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os\n",
    "from time import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('./spaMultiVAE/') \n",
    "\n",
    "os.environ['R_HOME'] = '/home/ws6tg/anaconda3/envs/EnvR43/lib/R/'\n",
    "import torch\n",
    "from spaMultiVAE import SPAMULTIVAE\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import h5py\n",
    "import scanpy as sc\n",
    "from preprocess import normalize, geneSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d779dbb-c695-4627-b401-4c83159f7c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../datasets/10x_human_lymph_node_D1/\"\n",
    "result_path=path.replace(\"datasets\",\"results\")\n",
    "\n",
    "'''\n",
    "Parameter setting\n",
    "'''\n",
    "\n",
    "class Args(object):\n",
    "    def __init__(self):\n",
    "        self.data_file = 'humantonsil_SVG.h5'\n",
    "        self.select_genes = 0\n",
    "        self.select_proteins = 0\n",
    "        self.batch_size = \"auto\"\n",
    "        self.maxiter = 100\n",
    "        self.train_size = 0.95\n",
    "        self.patience = 20\n",
    "        self.lr = 5e-3\n",
    "        self.weight_decay = 1e-6\n",
    "        self.gene_noise = 0\n",
    "        self.protein_noise = 0\n",
    "        self.dropoutE = 0\n",
    "        self.dropoutD = 0\n",
    "        self.encoder_layers = [128, 64]\n",
    "        self.GP_dim = 2\n",
    "        self.Normal_dim = 18\n",
    "        self.gene_decoder_layers = [128]\n",
    "        self.protein_decoder_layers = [128]\n",
    "        self.init_beta = 10\n",
    "        self.min_beta = 4\n",
    "        self.max_beta = 25\n",
    "        self.KL_loss = 0.025  \n",
    "        self.num_samples = 1\n",
    "        self.fix_inducing_points = True\n",
    "        self.inducing_point_steps = 19\n",
    "        self.fixed_gp_params = False\n",
    "        self.loc_range = 20.\n",
    "        self.kernel_scale = 20.\n",
    "        self.model_file = result_path+\"model.pt\"\n",
    "        self.final_latent_file = \"final_latent.txt\"\n",
    "        self.gene_denoised_counts_file = \"gene_denoised_counts.txt\"\n",
    "        self.protein_denoised_counts_file = \"protein_denoised_counts.txt\"\n",
    "        self.protein_sigmoid_file = \"protein_sigmoid.txt\"\n",
    "        self.gene_enhanced_denoised_counts_file = \"gene_enhanced_denoised_counts.txt\"\n",
    "        self.protein_enhanced_denoised_counts_file = \"protein_enhanced_denoised_counts.txt\"\n",
    "        self.enhanced_loc_file = \"enhanced_loc.txt\"\n",
    "        self.device = \"cuda:3\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# data_mat = h5py.File(args.data_file, 'r')\n",
    "adata2=sc.read_h5ad(path+\"adata_ADT.h5ad\")\n",
    "adata1=sc.read_h5ad(path+\"adata_RNA.h5ad\")\n",
    "\n",
    "\n",
    "x1 = np.array(adata1.X.toarray()).astype('float64')     # gene count matrix\n",
    "x2 = np.array(adata2.X.toarray()).astype('float64')  # protein count matrix\n",
    "loc = np.array(adata1.obsm[\"spatial\"]).astype('float64')       # location information\n",
    "\n",
    "if args.batch_size == \"auto\":\n",
    "    if x1.shape[0] <= 1024:\n",
    "        args.batch_size = 128\n",
    "    elif x1.shape[0] <= 2048:\n",
    "        args.batch_size = 256\n",
    "    else:\n",
    "        args.batch_size = 512\n",
    "else:\n",
    "    args.batch_size = int(args.batch_size)\n",
    "    \n",
    "print(args)\n",
    "\n",
    "if args.select_genes > 0:\n",
    "    importantGenes = geneSelection(x1, n=args.select_genes, plot=False)\n",
    "    x1 = x1[:, importantGenes]\n",
    "    np.savetxt(\"selected_genes.txt\", importantGenes, delimiter=\",\", fmt=\"%i\")\n",
    "\n",
    "if args.select_proteins > 0:\n",
    "    importantProteins = geneSelection(x2, n=args.select_proteins, plot=False)\n",
    "    x2 = x2[:, importantProteins]\n",
    "    np.savetxt(\"selected_proteins.txt\", importantProteins, delimiter=\",\", fmt=\"%i\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "loc = scaler.fit_transform(loc) * args.loc_range\n",
    "\n",
    "print(x1.shape)\n",
    "print(x2.shape)\n",
    "print(loc.shape)\n",
    "\n",
    "eps = 1e-5\n",
    "initial_inducing_points = np.mgrid[0:(1+eps):(1./args.inducing_point_steps), 0:(1+eps):(1./args.inducing_point_steps)].reshape(2, -1).T * args.loc_range\n",
    "print(initial_inducing_points.shape)\n",
    "\n",
    "adata1 = sc.AnnData(x1, dtype=\"float64\")\n",
    "adata1 = normalize(adata1,\n",
    "                  size_factors=True,\n",
    "                  filter_min_counts=False,\n",
    "                  normalize_input=True,\n",
    "                  logtrans_input=True)\n",
    "\n",
    "adata2 = sc.AnnData(x2, dtype=\"float64\")\n",
    "adata2 = normalize(adata2,\n",
    "                  size_factors=False,\n",
    "                  filter_min_counts=False,\n",
    "                  normalize_input=True,\n",
    "                  logtrans_input=True)\n",
    "adata2.X = np.nan_to_num(adata2.X, nan=0.0)\n",
    "\n",
    "adata2_no_scale = sc.AnnData(x2, dtype=\"float64\")\n",
    "adata2_no_scale = normalize(adata2_no_scale,\n",
    "                  size_factors=False,\n",
    "                  filter_min_counts=False,\n",
    "                  normalize_input=False,\n",
    "                  logtrans_input=True)\n",
    "\n",
    "\n",
    "adata2_no_scale.X = np.nan_to_num(adata2_no_scale.X, nan=0.0)  # 将NaN替换为0\n",
    "\n",
    "# Fit GMM model to the protein counts and use the smaller component as the initial values as protein background prior\n",
    "gm = GaussianMixture(n_components=2, covariance_type=\"diag\", n_init=20).fit(adata2_no_scale.X)\n",
    "back_idx = np.argmin(gm.means_, axis=0)\n",
    "protein_log_back_mean = np.log(np.expm1(gm.means_[back_idx, np.arange(adata2_no_scale.n_vars)]))\n",
    "protein_log_back_mean=np.nan_to_num(protein_log_back_mean, nan=0.0)\n",
    "protein_log_back_scale = np.sqrt(gm.covariances_[back_idx, np.arange(adata2_no_scale.n_vars)])\n",
    "print(\"protein_back_mean shape\", protein_log_back_mean.shape)\n",
    "\n",
    "model = SPAMULTIVAE(gene_dim=adata1.n_vars, protein_dim=adata2.n_vars, GP_dim=args.GP_dim, Normal_dim=args.Normal_dim, \n",
    "    encoder_layers=args.encoder_layers, gene_decoder_layers=args.gene_decoder_layers, protein_decoder_layers=args.protein_decoder_layers,\n",
    "    gene_noise=args.gene_noise, protein_noise=args.protein_noise, encoder_dropout=args.dropoutE, decoder_dropout=args.dropoutD,\n",
    "    fixed_inducing_points=args.fix_inducing_points, initial_inducing_points=initial_inducing_points, \n",
    "    fixed_gp_params=args.fixed_gp_params, kernel_scale=args.kernel_scale, N_train=adata1.n_obs, KL_loss=args.KL_loss, init_beta=args.init_beta, min_beta=args.min_beta, \n",
    "    max_beta=args.max_beta, protein_back_mean=protein_log_back_mean, protein_back_scale=protein_log_back_scale, dtype=torch.float64, \n",
    "    device=args.device,dynamicVAE=False)\n",
    "\n",
    "print(str(model))\n",
    "\n",
    "if not os.path.isfile(args.model_file):\n",
    "    t0 = time()\n",
    "    model.train_model(pos=loc, gene_ncounts=adata1.X, gene_raw_counts=adata1.raw.to_adata().X, gene_size_factors=adata1.obs[\"size_factors\"].values, \n",
    "                protein_ncounts=adata2.X, protein_raw_counts=adata2.raw.to_adata().X,\n",
    "                lr=args.lr, weight_decay=args.weight_decay, batch_size=args.batch_size, num_samples=args.num_samples,\n",
    "                train_size=1, maxiter=args.maxiter, patience=args.patience, save_model=True, model_weights=args.model_file)\n",
    "    print('Training time: %d seconds.' % int(time() - t0))\n",
    "else:\n",
    "    model.load_model(args.model_file)\n",
    "\n",
    "final_latent = model.batching_latent_samples(X=loc, gene_Y=adata1.X, protein_Y=adata2.X, batch_size=args.batch_size)\n",
    "\n",
    "adata=sc.read_h5ad(path+\"adata_RNA.h5ad\")\n",
    "adata.obsm[\"X_SpaMultiVAE\"]=final_latent\n",
    "\n",
    "adata.write_h5ad(path.replace(\"datasets\",\"results\")+\"adataSpaMultiVAE.h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scvi",
   "language": "python",
   "name": "scvi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
